{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "\n",
    "import simplejson as json \n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageStat \n",
    "import requests\n",
    "import glob\n",
    "import time\n",
    "from datetime import date\n",
    "import http.client, urllib.request \n",
    "import urllib.parse, urllib.error \n",
    "import base64, sys \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign in Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signin(file='config.txt'):\n",
    "\n",
    "    driver.get('https://www.linkedin.com/login')\n",
    "\n",
    "    #Login credentials for Linkedin\n",
    "    file=open(file)\n",
    "    lines=file.readlines()\n",
    "    username=lines[0]\n",
    "    password=lines[1]\n",
    "\n",
    "    # locate username and password form login page by HTML id\n",
    "    enter_username = driver.find_element_by_id('username')\n",
    "    enter_password=driver.find_element_by_id('password')\n",
    "\n",
    "    # send_keys() to simulate key strokes\n",
    "    enter_username.send_keys(username)\n",
    "    enter_password.send_keys(password)\n",
    "\n",
    "    #Submit Credentials\n",
    "    enter_password.submit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scroll Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll():\n",
    "    SCROLL_PAUSE_TIME = 2\n",
    "    \n",
    "    #Scroll to see more and click if visible\n",
    "    \n",
    "    driver.execute_script(\"window.scrollTo(0,560);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_id('line-clamp-show-more-button').click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Scroll back to top \n",
    "    \n",
    "    driver.execute_script(\"window.scrollTo(0,0);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcitions for Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_name():\n",
    "    name_all= soup.find('div',{'class':'flex-1 mr5'})#\n",
    "    name=name_all.find('li',{'class':'inline t-24 t-black t-normal break-words'}).get_text().strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_image():\n",
    "    imgtag=soup.select('img[title]')\n",
    "    urllib.request.urlretrieve(imgtag[0]['src'],'scraped_image.jpg')\n",
    "    return imgtag[0]['src']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_about():\n",
    "    try:\n",
    "        about_all= soup.find('span',{'class':'lt-line-clamp__raw-line'}).get_text().strip()\n",
    "        return about_all\n",
    "    except:\n",
    "        return 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_header():\n",
    "    name_all= soup.find('div',{'class':'flex-1 mr5'})\n",
    "    header=name_all.find_all('h2')[0].get_text().strip()\n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_location():\n",
    "    name_all= soup.find('div',{'class':'flex-1 mr5'})\n",
    "    location=name_all.find_all('li')[2].get_text().strip()\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_connections():\n",
    "    name_all= soup.find('div',{'class':'flex-1 mr5'})\n",
    "    connections=name_all.find_all('li')[3].get_text().strip()\n",
    "    return connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_joining():\n",
    "    company_all= soup.find('div',{'class':'pv-entity__summary-info pv-entity__summary-info--background-section'})\n",
    "    joining=company_all.find_all('span')[2].get_text().strip()\n",
    "    return joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_experience():\n",
    "    company_all= soup.find('div',{'class':'pv-entity__summary-info pv-entity__summary-info--background-section'})\n",
    "    experience=company_all.find_all('span')[4].get_text().strip()\n",
    "    return experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_company():\n",
    "    company_all= soup.find('div',{'class':'pv-entity__summary-info pv-entity__summary-info--background-section'})\n",
    "    company=company_all.find_all('p')[1].get_text().strip().split('\\n')[0]\n",
    "    return company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_title():\n",
    "    company_all= soup.find('div',{'class':'pv-entity__summary-info pv-entity__summary-info--background-section'})\n",
    "    title=company_all.find_all('h3')[0].get_text().strip()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_college():\n",
    "    college_all= soup.find('div',{'class':'pv-entity__degree-info'})\n",
    "    college=college_all.find_all('h3')[0].get_text().strip()\n",
    "    return college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_degree():\n",
    "    college_all= soup.find('div',{'class':'pv-entity__degree-info'})\n",
    "    degree=college_all.find_all('span')[1].get_text().strip()\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape_degree_year():\n",
    "    college_all= soup.find_all('time')\n",
    "    year1=college_all[0].get_text().strip()\n",
    "    year2=college_all[1].get_text().strip()\n",
    "    year=year1 +'-'+ year2\n",
    "    return year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login to Linkedin and enter profiles to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('Link.csv')\n",
    "\n",
    "dates=[]\n",
    "name=[]\n",
    "image=[]\n",
    "about=[]\n",
    "header=[]\n",
    "location=[]\n",
    "connections=[]\n",
    "joining=[]\n",
    "experience=[]\n",
    "company=[]\n",
    "title=[]\n",
    "college=[]\n",
    "degree=[]\n",
    "degree_year=[]\n",
    "# attributes for image analysis  \n",
    "Brightness=[]\n",
    "Face=[]\n",
    "No_of_faces=[]\n",
    "Face_area=[]\n",
    "Bluriness=[]\n",
    "# attributes for image score\n",
    "img_score=[]\n",
    "image_comments=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-550-dc7d285d88dc>:7: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  dates.append(pd.datetime.today().strftime('%d %b, %Y'))\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "signin()\n",
    "for link in df1.URL.values:\n",
    "    Linkedin_url = link\n",
    "    driver.get(Linkedin_url)\n",
    "    soup=scroll()\n",
    "    dates.append(pd.datetime.today().strftime('%d %b, %Y'))\n",
    "    \n",
    "    #Scrapping data and appending it to lists\n",
    "    name.append(Scrape_name())\n",
    "    image.append(Scrape_image())\n",
    "    about.append(Scrape_about())\n",
    "    header.append(Scrape_header())\n",
    "    location.append(Scrape_location())\n",
    "    connections.append(Scrape_connections())\n",
    "    joining.append(Scrape_joining())\n",
    "    experience.append(Scrape_experience())\n",
    "    company.append(Scrape_company())\n",
    "    title.append(Scrape_title())\n",
    "    college.append(Scrape_college())\n",
    "    degree.append(Scrape_degree())\n",
    "    degree_year.append(Scrape_degree_year())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image urls to jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ancy Rex.jpg saved.\n",
      "Aarsha Treesa Joseph.jpg saved.\n",
      "Sophia Binod.jpg saved.\n",
      "Arpitha Tini Daniel.jpg saved.\n"
     ]
    }
   ],
   "source": [
    "# converting image urls to jpg files \n",
    "def url_to_jpg(i, url, file_path):\n",
    "    # converting url to jpg format\n",
    "    ext=\".jpg\"\n",
    "    file_name = name[i]+ext.format(i) # photo saved under user's full name\n",
    "    full_path = '{}{}'.format(file_path,file_name)\n",
    "    urllib.request.urlretrieve(url,full_path)\n",
    "    print('{} saved.'.format(file_name))\n",
    "    return None\n",
    " \n",
    "FILENAME = pd.DataFrame(image)\n",
    "FILEPATH = '/Users/ancy_rex/imageanalytics/images/'\n",
    "\n",
    "urls = FILENAME\n",
    "\n",
    "for i, url in enumerate(urls.values):\n",
    "    #calling the function for each user's link\n",
    "    url_to_jpg(i, url[0], FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_analysis(i):\n",
    "    # path for each user image \n",
    "    ext=\".jpg\"\n",
    "    file_name = name[i]+ext\n",
    "    path = '/Users/ancy_rex/imageanalytics/images/'+file_name\n",
    "    \n",
    "    #opening the image using imread for BGR2GRAY conversion\n",
    "    image  =  cv2.imread(path)\n",
    "    gray_image  =  cv2.cvtColor(image,  cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #acquire total area of the image\n",
    "    total_area = len(image)**2\n",
    "\n",
    "    # obtain the number of faces in the image\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray_image, 1.3, 5)\n",
    "\n",
    "    # initialisation\n",
    "    image_brightness = 0\n",
    "    face = \"Not Visible\"\n",
    "    no_of_faces = 0\n",
    "    face_area = 0.0\n",
    "    image_bluriness = 0.0\n",
    "    \n",
    "    # checking for only 1 face in the image\n",
    "    if len(faces)==0 or len(faces)>1:\n",
    "        image_brightness = 0\n",
    "        face = \"Not Visible\"\n",
    "        no_of_faces = 0\n",
    "        face_area = 0\n",
    "        image_bluriness = 0\n",
    "        \n",
    "    # calculating image attributes if image has 1 face\n",
    "    elif len(faces)==1:\n",
    "        no_of_faces = len(faces)\n",
    "        face = \"Visible\"\n",
    "        \n",
    "        # converting image to luminous mode\n",
    "        img  =  Image.open(path).convert('L')\n",
    "        stat = ImageStat.Stat(img) #achieve each pixel brightness\n",
    "        image_brightness  =  round(stat.mean[0]) #achieve average brightness\n",
    "        \n",
    "        for  (sx,sy,sw,sh) in faces: #finding area of the face \n",
    "            cv2.rectangle(image,(sx,sy),(sx+sw,sy+sh),(255,0,0),2)# drawing rectangle around the face\n",
    "            crop_image = image[sy:sy+sh, sx:sx+sw] # the face part is cropped\n",
    "            roi_gray = gray_image[sy:sy+sh, sx:sx+sw] \n",
    "            roi_color = image[sy:sy+sh, sx:sx+sw]\n",
    "            face_area = round(sw*sh*100/total_area, 2) #area occupied by the face\n",
    "            laplace  =  cv2.Laplacian(gray_image,  cv2.CV_64F).var()  #laplace transform\n",
    "            image_bluriness = round(laplace, 2)\n",
    "            \n",
    "            face_gray  =  cv2.cvtColor(crop_image,  cv2.COLOR_BGR2GRAY)\n",
    "            laplace  =  cv2.Laplacian(gray_image,  cv2.CV_64F).var()  #face laplace transform\n",
    "            face_bluriness =\tround(laplace, 2) #bluriness of the face\n",
    "            \n",
    "    #appending all image attribute values\n",
    "    Brightness.append(image_brightness)\n",
    "    Face.append(face)\n",
    "    No_of_faces.append(no_of_faces)\n",
    "    Face_area.append(face_area)\n",
    "    Bluriness.append(image_bluriness)\n",
    "    return(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for scoring profile photo\n",
    "def image_score(brightness,face_area,bluriness,nooffaces):\n",
    "    comments = []\n",
    "    #initial photo score\n",
    "    image_score = 15\n",
    "    # scoring zero for not recognising the face or more than 1 recognised face\n",
    "    if(nooffaces==0 or nooffaces>1):\n",
    "        image_score = 0\n",
    "        comments.append('Image should only contain your face')\n",
    "    #scoring photo based on other attribute values and respective comments updated\n",
    "    else:\n",
    "        if(face_area < 35.0):\n",
    "            image_score = image_score - 5\n",
    "            comments.append('The image should accomodate more of your face')\n",
    "        if(brightness < 100):\n",
    "            image_score = image_score - 1\n",
    "            comments.append('The Image requires more brightness')\n",
    "        if(bluriness > 75):\n",
    "            image_score = image_score - 1\n",
    "            comments.append('The image is too blured')\n",
    "    return(image_score,comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clear the lists for junk/previous values\n",
    "def clear_list():\n",
    "    Brightness.clear()\n",
    "    Face.clear()\n",
    "    No_of_faces.clear()\n",
    "    Face_area.clear()\n",
    "    Bluriness.clear()\n",
    "    img_scr.clear()\n",
    "    img_comments.clear()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing the list for new values \n",
    "clear_list()\n",
    "\n",
    "# calling image analysis function for each profile photo\n",
    "for i in range(0,len(df1)):\n",
    "    \n",
    "    img = image_analysis(i)\n",
    "    \n",
    "    # call image score function while passing attributes\n",
    "    face_area=Face_area[i]\n",
    "    brightness= Brightness[i]\n",
    "    bluriness= Bluriness[i]\n",
    "    nooffaces = No_of_faces[i]\n",
    "    score,comment=image_score(brightness,face_area,bluriness,nooffaces)\n",
    "    \n",
    "    # appending score and comment for each user\n",
    "    img_score.append(score)\n",
    "    image_comments.append(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>image</th>\n",
       "      <th>about</th>\n",
       "      <th>header</th>\n",
       "      <th>location</th>\n",
       "      <th>connections</th>\n",
       "      <th>joining</th>\n",
       "      <th>experience</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>college</th>\n",
       "      <th>degree</th>\n",
       "      <th>degree_year</th>\n",
       "      <th>Image Score</th>\n",
       "      <th>Image comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16 Aug, 2020</td>\n",
       "      <td>Ancy Rex</td>\n",
       "      <td>https://media-exp1.licdn.com/dms/image/C5603AQ...</td>\n",
       "      <td>Master of Data Science student with highly dev...</td>\n",
       "      <td>Data Analyst Intern at AI Australia | Masters ...</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>159 connections</td>\n",
       "      <td>Employment Duration</td>\n",
       "      <td>Location</td>\n",
       "      <td>AI Australia</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>RMIT University</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>2019-2021</td>\n",
       "      <td>14</td>\n",
       "      <td>[The image is too blured]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16 Aug, 2020</td>\n",
       "      <td>Aarsha Treesa Joseph</td>\n",
       "      <td>https://media-exp1.licdn.com/dms/image/C5603AQ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Business Analytics  Student at Deakin University</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>64 connections</td>\n",
       "      <td>Employment Duration</td>\n",
       "      <td>Location</td>\n",
       "      <td>Coles</td>\n",
       "      <td>Team member</td>\n",
       "      <td>Deakin University</td>\n",
       "      <td>Masters</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>9</td>\n",
       "      <td>[The image should accomodate more of your face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16 Aug, 2020</td>\n",
       "      <td>Sophia Binod</td>\n",
       "      <td>https://media-exp1.licdn.com/dms/image/C5603AQ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Student Business Analyst at Deakin University,...</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>101 connections</td>\n",
       "      <td>Employment Duration</td>\n",
       "      <td>Location</td>\n",
       "      <td>Deakin University</td>\n",
       "      <td>Student Volunteer</td>\n",
       "      <td>Deakin University</td>\n",
       "      <td>Masters</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>[Image should only contain your face]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16 Aug, 2020</td>\n",
       "      <td>Arpitha Tini Daniel</td>\n",
       "      <td>https://media-exp1.licdn.com/dms/image/C5103AQ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Engineering Management student at Deakin Unive...</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>90 connections</td>\n",
       "      <td>Dec 2019 – May 2020</td>\n",
       "      <td>6 mos</td>\n",
       "      <td>UniLodge Australia</td>\n",
       "      <td>Residential Advisor</td>\n",
       "      <td>Deakin University</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>2019-2021</td>\n",
       "      <td>9</td>\n",
       "      <td>[The image should accomodate more of your face...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                  name  \\\n",
       "0  16 Aug, 2020              Ancy Rex   \n",
       "1  16 Aug, 2020  Aarsha Treesa Joseph   \n",
       "2  16 Aug, 2020          Sophia Binod   \n",
       "3  16 Aug, 2020   Arpitha Tini Daniel   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://media-exp1.licdn.com/dms/image/C5603AQ...   \n",
       "1  https://media-exp1.licdn.com/dms/image/C5603AQ...   \n",
       "2  https://media-exp1.licdn.com/dms/image/C5603AQ...   \n",
       "3  https://media-exp1.licdn.com/dms/image/C5103AQ...   \n",
       "\n",
       "                                               about  \\\n",
       "0  Master of Data Science student with highly dev...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "\n",
       "                                              header  \\\n",
       "0  Data Analyst Intern at AI Australia | Masters ...   \n",
       "1   Business Analytics  Student at Deakin University   \n",
       "2  Student Business Analyst at Deakin University,...   \n",
       "3  Engineering Management student at Deakin Unive...   \n",
       "\n",
       "                         location      connections              joining  \\\n",
       "0  Melbourne, Victoria, Australia  159 connections  Employment Duration   \n",
       "1  Melbourne, Victoria, Australia   64 connections  Employment Duration   \n",
       "2  Melbourne, Victoria, Australia  101 connections  Employment Duration   \n",
       "3  Melbourne, Victoria, Australia   90 connections  Dec 2019 – May 2020   \n",
       "\n",
       "  experience             company                title            college  \\\n",
       "0   Location        AI Australia  Data Analyst Intern    RMIT University   \n",
       "1   Location               Coles          Team member  Deakin University   \n",
       "2   Location   Deakin University    Student Volunteer  Deakin University   \n",
       "3      6 mos  UniLodge Australia  Residential Advisor  Deakin University   \n",
       "\n",
       "            degree degree_year  Image Score  \\\n",
       "0  Master's degree   2019-2021           14   \n",
       "1          Masters   2019-2020            9   \n",
       "2          Masters   2019-2020            0   \n",
       "3  Master's degree   2019-2021            9   \n",
       "\n",
       "                                      Image comments  \n",
       "0                          [The image is too blured]  \n",
       "1  [The image should accomodate more of your face...  \n",
       "2              [Image should only contain your face]  \n",
       "3  [The image should accomodate more of your face...  "
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin = {'date':dates,'name':name,'image':image,'about':about,'header':header,'location':location,'connections':connections,\\\n",
    "            'joining':joining,'experience':experience,'company':company,'title':title,'college':college,'degree':degree,\\\n",
    "            'degree_year':degree_year,'Image Score':img_score,'Image comments':image_comments}  \n",
    "    \n",
    "linkedin_df = pd.DataFrame(linkedin) \n",
    "linkedin_df.to_csv('Linkedin_profiles.csv')\n",
    "linkedin_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
